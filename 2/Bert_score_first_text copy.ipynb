{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b96c13e",
   "metadata": {},
   "source": [
    "## Προσθέτουμε τις απαραίτητες βιβλιοθήκες"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89614eb8",
   "metadata": {},
   "source": [
    "## Σημείωση : Η sentence_transformers χρησιμοποιεί pre-trained μοντέλα για την παραγωγή embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1030398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01d824",
   "metadata": {},
   "source": [
    "## Κώδικας για να ανοίξουμε και να συλλέξουμε το αρχικό κείμενο αλλά και τα αποτελέσματα των pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3e3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_files(path):  \n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            print(\"File content successfully loaded.\")\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The file  was not found. Please make sure the file exists and the path is correct.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9f1200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File content successfully loaded.\n",
      "File content successfully loaded.\n",
      "File content successfully loaded.\n",
      "File content successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "paths=[\"../text_files/text1.txt\",\"../text_files/first_pipeline_text1.txt\",\"../text_files/second_pipeline_text1.txt\",\"../text_files/third_pipeline_text1.txt\"]\n",
    "texts=[]\n",
    "for path in paths:\n",
    "    texts.append(take_files(path))\n",
    "original_text=texts[0]\n",
    "pipeline1=texts[1]\n",
    "pipeline2=texts[2]\n",
    "pipeline3=texts[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf326e1b",
   "metadata": {},
   "source": [
    "## Αποθήκευση των ground truth's με βάση τα οποία θα γίνει η σύγκριση\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e27323",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini=\"\"\"Happy Dragon Boat Festival! I hope you're celebrating safely and enjoying a wonderful time.\n",
    "\n",
    "Thank you for relaying our message to the doctor regarding his contract review. I actually received the approved message from the professor a couple of days ago. I'm very grateful for the professor's full support with our Springer proceedings publication.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e215d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek=\"\"\"Today is our Dragon Boat Festival, a cherished celebration in Chinese culture. I wish you safety, joy, and prosperity during this time—may you enjoy the festivities as deeply as I hope for you.\n",
    "\n",
    "Thank you for sharing the message regarding the doctor’s contract review. I’ve already received the approved notice from the professor a few days ago and sincerely appreciate their unwavering support for our Springer proceedings publication.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1cb0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_gpt=\"\"\"Today is our Dragon Boat Festival, a special celebration in our Chinese culture. It is a time to honor and wish for safety and prosperity in our lives. I hope you also enjoy this festival, as I send you my warmest wishes.\n",
    "\n",
    "Thank you for your message and for conveying our words to the doctor regarding his upcoming contract review. This is important for all of us.\n",
    "\n",
    "I received this message to confirm the approval. Actually, the professor shared this with me a couple of days ago. I truly appreciate the professor’s full support for our Springer proceedings publication.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0752cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    \"pipeline1\": pipeline1,\n",
    "    \"pipeline2\": pipeline2,\n",
    "    \"pipeline3\": pipeline3,\n",
    "}\n",
    "\n",
    "llms = {\n",
    "    \"chatgpt\":  chat_gpt,\n",
    "    \"gemini\":   gemini,\n",
    "    \"deepseek\": deepseek,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a1e19b",
   "metadata": {},
   "source": [
    "## Το bert_model υπολογίζει bert score και το embed_model χρησιμοποιεί έτοιμα embeddings και cosine similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf36a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model  = \"bert-base-uncased\"                  \n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd5f2fc",
   "metadata": {},
   "source": [
    "## Φτιάχνουμε ένα λεξικό embeddings,όπου key το όνομα του αντικειμένου και value η κωδικοποίηση του σε embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddb51552",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = { **pipelines, **llms }\n",
    "embeddings = {\n",
    "    name: embed_model.encode(text, convert_to_tensor=True)\n",
    "    for name, text in all_texts.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d1d3d5",
   "metadata": {},
   "source": [
    "## Υπολογισμός Σκορ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a94890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69ed33fb06a4f9bb0257b79fccd3cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexi\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\alexi\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51151dc55be749afabbf4e5fc24833e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5e4d89255e4085b7321fb5f1e10438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393b0808627440cfb03468637261d880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed61559d0905411fa788d6bf7d5f15cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "for l_name, l_text in llms.items():\n",
    "    for p_name, p_text in pipelines.items():\n",
    "        # BERTScore (wrap in lists)\n",
    "        P, R, F1 = score([p_text], [l_text],\n",
    "                         lang=\"en\",\n",
    "                         model_type=bert_model,\n",
    "                         verbose=False,\n",
    "                         device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        bP, bR, bF1 = float(P.mean()), float(R.mean()), float(F1.mean())\n",
    "\n",
    "        # Embedding cosine similarity\n",
    "        pe = embeddings[p_name]\n",
    "        le = embeddings[l_name]\n",
    "        cos = (pe @ le) / (pe.norm() * le.norm())\n",
    "\n",
    "        rows.append({\n",
    "            \"Pipeline\":       p_name,\n",
    "            \"LLM\":            l_name,\n",
    "            \"BERTScore_P\":    bP,\n",
    "            \"BERTScore_R\":    bR,\n",
    "            \"BERTScore_F1\":   bF1,\n",
    "            \"Embed_Cosine\":   float(cos)\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc0be69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>LLM</th>\n",
       "      <th>BERTScore_P</th>\n",
       "      <th>BERTScore_R</th>\n",
       "      <th>BERTScore_F1</th>\n",
       "      <th>Embed_Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pipeline1</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>0.776396</td>\n",
       "      <td>0.771578</td>\n",
       "      <td>0.773979</td>\n",
       "      <td>0.962389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pipeline2</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>0.777926</td>\n",
       "      <td>0.775032</td>\n",
       "      <td>0.776476</td>\n",
       "      <td>0.954267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pipeline3</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>0.578537</td>\n",
       "      <td>0.707876</td>\n",
       "      <td>0.636704</td>\n",
       "      <td>0.794937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pipeline1</td>\n",
       "      <td>gemini</td>\n",
       "      <td>0.656933</td>\n",
       "      <td>0.767745</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.878521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pipeline2</td>\n",
       "      <td>gemini</td>\n",
       "      <td>0.665038</td>\n",
       "      <td>0.783617</td>\n",
       "      <td>0.719474</td>\n",
       "      <td>0.876309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pipeline3</td>\n",
       "      <td>gemini</td>\n",
       "      <td>0.508684</td>\n",
       "      <td>0.716024</td>\n",
       "      <td>0.594803</td>\n",
       "      <td>0.718989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pipeline1</td>\n",
       "      <td>deepseek</td>\n",
       "      <td>0.667285</td>\n",
       "      <td>0.700117</td>\n",
       "      <td>0.683307</td>\n",
       "      <td>0.936935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pipeline2</td>\n",
       "      <td>deepseek</td>\n",
       "      <td>0.667135</td>\n",
       "      <td>0.701651</td>\n",
       "      <td>0.683958</td>\n",
       "      <td>0.935804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pipeline3</td>\n",
       "      <td>deepseek</td>\n",
       "      <td>0.511285</td>\n",
       "      <td>0.639596</td>\n",
       "      <td>0.568288</td>\n",
       "      <td>0.806194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pipeline       LLM  BERTScore_P  BERTScore_R  BERTScore_F1  Embed_Cosine\n",
       "0  pipeline1   chatgpt     0.776396     0.771578      0.773979      0.962389\n",
       "1  pipeline2   chatgpt     0.777926     0.775032      0.776476      0.954267\n",
       "2  pipeline3   chatgpt     0.578537     0.707876      0.636704      0.794937\n",
       "3  pipeline1    gemini     0.656933     0.767745      0.708029      0.878521\n",
       "4  pipeline2    gemini     0.665038     0.783617      0.719474      0.876309\n",
       "5  pipeline3    gemini     0.508684     0.716024      0.594803      0.718989\n",
       "6  pipeline1  deepseek     0.667285     0.700117      0.683307      0.936935\n",
       "7  pipeline2  deepseek     0.667135     0.701651      0.683958      0.935804\n",
       "8  pipeline3  deepseek     0.511285     0.639596      0.568288      0.806194"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b479357",
   "metadata": {},
   "source": [
    "### Σύντομη Επεξήγηση Μετρικών\n",
    "\n",
    "- **BERTScore Precision (P)**  \n",
    "  Από τα token που παράγει το pipeline, ποιο ποσοστό βρίσκει “αντίστοιχα” token μέσα στην έξοδο του LLM. Μετράει πόσο «στοχευμένη» είναι η παραγωγή του pipeline σε σχέση με την αναφορά(ground truth).\n",
    "\n",
    "- **BERTScore Recall (R)**  \n",
    "  Από τα token που έχει το LLM, ποιο ποσοστό καλύπτεται από τα token του pipeline. Δείχνει πόσο πλήρες είναι το pipeline σε σχέση με την αναφορά(ground truth).\n",
    "\n",
    "- **BERTScore F1**  \n",
    "  Ο  μέσος του Precision και του Recall. Ισορροπεί την ποιότητα (P) με την κάλυψη (R) σε ένα ενιαίο σκορ 0-1.\n",
    "\n",
    "- **Cosine Similarity (Embed_Cosine)**  \n",
    "  Συνητινιμική ομοιότητα ανάμεσα στα ολόκληρα embeddings (διάνυσμα) δύο κειμένων. Τιμή 1 σημαίνει ταυτόσημη κατεύθυνση, 0 σημαίνει ορθογώνια (καμιά σχέση).  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
