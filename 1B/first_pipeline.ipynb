{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb3aa20",
   "metadata": {},
   "source": [
    "## Βήματα υλοποίηση του pipeline\n",
    "##### α) Διάβασμα αρχείων κειμένων\n",
    "##### β) Επιλογή pipeline\n",
    "##### γ) Ανακατασκευή του κειμένου \n",
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d27c2",
   "metadata": {},
   "source": [
    "### α) Διάβασμα αρχείων κειμένων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422cea9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File content successfully loaded into text1.\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    with open('../text_files/text1.txt', 'r', encoding='utf-8') as file:\n",
    "        text1 = file.read()\n",
    "    print(\"File content successfully loaded into text1.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'text1.txt' was not found. Please make sure the file exists and the path is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b0fc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File content successfully loaded into text2.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('../text_files/text2.txt', 'r', encoding='utf-8') as file:\n",
    "        text2 = file.read()\n",
    "    print(\"File content successfully loaded into text2.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'text2.txt' was not found. Please make sure the file exists and the path is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa74f4c",
   "metadata": {},
   "source": [
    "### β) Επιλογή pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a55def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model={ \"Grammar Correction (vennify)\": pipeline(\"text2text-generation\", model=\"vennify/t5-base-grammar-correction\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d6e103",
   "metadata": {},
   "source": [
    "### γ) Ανακατασκευή του κειμένου "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34824225",
   "metadata": {},
   "source": [
    "- Χωρίζουμε τα κείμενα σε προτάσεις"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d976d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences_text1 = sent_tokenize(text1)\n",
    "sentences_text2 = sent_tokenize(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eab2d4c",
   "metadata": {},
   "source": [
    "- Κάνουμε Loop για κάθε πρόταση και πραγματοποιούμε ανακατασκευή"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2f37e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in\n",
      "our lives.\n",
      "→ Transformed: Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safety and great in our lives.\n",
      "\n",
      "Original: Hope you too, to enjoy it as my deepest wishes.\n",
      "→ Transformed: Hope you too, enjoy it as my deepest wishes.\n",
      "\n",
      "Original: Thank your message to show our words to the doctor, as his next contract checking, to all of us.\n",
      "→ Transformed: Thank you for your message to show our words to the doctor, as his next contract checking, to all of us.\n",
      "\n",
      "Original: I got this message to see the approved message.\n",
      "→ Transformed: I got this message to see the approved message.\n",
      "\n",
      "Original: In fact, I have received the message from the\n",
      "professor, to show me, this, a couple of days ago.\n",
      "→ Transformed: In fact, I have received the message from the professor, to show me, this, a couple of days ago.\n",
      "\n",
      "Original: I am very appreciated the full support of the\n",
      "professor, for our Springer proceedings publication.\n",
      "→ Transformed: I am very appreciated the full support of the professor, for our Springer proceedings publication.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reconstructed_text1=\"\"\n",
    "for sentence in sentences_text1:\n",
    "     model_pipeline= model[\"Grammar Correction (vennify)\"]\n",
    "     result = model_pipeline(sentence, max_length=256, do_sample=False)[0][\"generated_text\"]\n",
    "     print(f\"Original: {sentence}\")\n",
    "     print(f\"→ Transformed: {result}\\n\")\n",
    "     reconstructed_text1+=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051f54ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: During our final discuss, I told him about the new submission — the one we were waiting since\n",
      "        last autumn, but the updates was confusing as it not included the full feedback from reviewer or\n",
      "        maybe editor?\n",
      "→ Transformed: During our final discuss, I told him about the new submission — the one we were waiting for since last autumn, but the updates were confusing as it did not include the full feedback from reviewer or maybe editor.\n",
      "\n",
      "Original: Anyway, I believe the team, although bit delay and less communication at recent days, they really\n",
      "        tried best for paper and cooperation.\n",
      "→ Transformed: Anyway, I believe the team, although there was a bit of delay and less communication at recent days, they really tried best for paper and cooperation.\n",
      "\n",
      "Original: We should be grateful, I mean all of us, for the acceptance\n",
      "        and efforts until the Springer link came finally last week, I think.\n",
      "→ Transformed: We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link finally came last week, I think.\n",
      "\n",
      "Original: Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before\n",
      "        he sending again.\n",
      "→ Transformed: Also, please remind me, if the doctor still plans for the acknowledgments section edit before he sends again.\n",
      "\n",
      "Original: Because I didn’t see that part final yet, or maybe I missed, I apologize if so.\n",
      "→ Transformed: Because I didn’t see that part final yet, or maybe I missed, I apologize if so.\n",
      "\n",
      "Original: Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future\n",
      "        targets.\n",
      "→ Transformed: Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reconstructed_text2=\"\"\n",
    "for sentence in sentences_text2:\n",
    "     model_pipeline= model[\"Grammar Correction (vennify)\"]\n",
    "     result = model_pipeline(sentence, max_length=256, do_sample=False)[0][\"generated_text\"]\n",
    "     print(f\"Original: {sentence}\")\n",
    "     print(f\"→ Transformed: {result}\\n\")\n",
    "     reconstructed_text2+=result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e184ba4e",
   "metadata": {},
   "source": [
    "### Αποθηκεύουμε τα ανακατασκευασμένα κείμενα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82403457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved reconstructed text \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"../text_files/first_pipeline_text1.txt\", 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(reconstructed_text1)\n",
    "    print(f\"Successfully saved reconstructed text \")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "321740e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved reconstructed text \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"../text_files/first_pipeline_text2.txt\", 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(reconstructed_text2)\n",
    "    print(f\"Successfully saved reconstructed text \")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file : {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
