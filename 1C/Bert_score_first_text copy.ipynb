{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b96c13e",
   "metadata": {},
   "source": [
    "## Προσθέτουμε τις απαραίτητες βιβλιοθήκες"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89614eb8",
   "metadata": {},
   "source": [
    "## Σημείωση : Η sentence_transformers χρησιμοποιεί pre-trained μοντέλα για την παραγωγή embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1030398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01d824",
   "metadata": {},
   "source": [
    "## Κώδικας για να ανοίξουμε και να συλλέξουμε το αρχικό κείμενο αλλά και τα αποτελέσματα των pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b3e3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_files(path):  \n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            print(\"File content successfully loaded.\")\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The file  was not found. Please make sure the file exists and the path is correct.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e9f1200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File content successfully loaded.\n",
      "File content successfully loaded.\n",
      "File content successfully loaded.\n",
      "File content successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "paths=[\"../text_files/text1.txt\",\"../text_files/first_pipeline_text1.txt\",\"../text_files/second_pipeline_text1.txt\",\"../text_files/third_pipeline_text1.txt\"]\n",
    "texts=[]\n",
    "for path in paths:\n",
    "    texts.append(take_files(path))\n",
    "original_text=texts[0]\n",
    "pipeline1=texts[1]\n",
    "pipeline2=texts[2]\n",
    "pipeline3=texts[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf326e1b",
   "metadata": {},
   "source": [
    "## Αποθήκευση των ground truth's με βάση τα οποία θα γίνει η σύγκριση\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0e27323",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini=\"\"\"Happy Dragon Boat Festival! I hope you're celebrating safely and enjoying a wonderful time.\n",
    "\n",
    "Thank you for relaying our message to the doctor regarding his contract review. I actually received the approved message from the professor a couple of days ago. I'm very grateful for the professor's full support with our Springer proceedings publication.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e215d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek=\"\"\"Today is our Dragon Boat Festival, a cherished celebration in Chinese culture. I wish you safety, joy, and prosperity during this time—may you enjoy the festivities as deeply as I hope for you.\n",
    "\n",
    "Thank you for sharing the message regarding the doctor’s contract review. I’ve already received the approved notice from the professor a few days ago and sincerely appreciate their unwavering support for our Springer proceedings publication.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1cb0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_gpt=\"\"\"Today is our Dragon Boat Festival, a special celebration in our Chinese culture. It is a time to honor and wish for safety and prosperity in our lives. I hope you also enjoy this festival, as I send you my warmest wishes.\n",
    "\n",
    "Thank you for your message and for conveying our words to the doctor regarding his upcoming contract review. This is important for all of us.\n",
    "\n",
    "I received this message to confirm the approval. Actually, the professor shared this with me a couple of days ago. I truly appreciate the professor’s full support for our Springer proceedings publication.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0752cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    \"pipeline1\": pipeline1,\n",
    "    \"pipeline2\": pipeline2,\n",
    "    \"pipeline3\": pipeline3,\n",
    "}\n",
    "\n",
    "llms = {\n",
    "    \"chatgpt\":  chat_gpt,\n",
    "    \"gemini\":   gemini,\n",
    "    \"deepseek\": deepseek,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a1e19b",
   "metadata": {},
   "source": [
    "## Το bert_model υπολογίζει bert score και το embed_model χρησιμοποιεί έτοιμα embeddings και cosine similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cf36a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model  = \"bert-base-uncased\"                  \n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd5f2fc",
   "metadata": {},
   "source": [
    "## Φτιάχνουμε ένα λεξικό embeddings,όπου key το όνομα του αντικειμένου και value η κωδικοποίηση του σε embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddb51552",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = { **pipelines, **llms }\n",
    "embeddings = {\n",
    "    name: embed_model.encode(text, convert_to_tensor=True)\n",
    "    for name, text in all_texts.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d1d3d5",
   "metadata": {},
   "source": [
    "## Υπολογισμός Σκορ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5a94890",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for l_name, l_text in llms.items():\n",
    "    for p_name, p_text in pipelines.items():\n",
    "        # BERTScore (wrap in lists)\n",
    "        P, R, F1 = score([p_text], [l_text],\n",
    "                         lang=\"en\",\n",
    "                         model_type=bert_model,\n",
    "                         verbose=False,\n",
    "                         device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        bP, bR, bF1 = float(P.mean()), float(R.mean()), float(F1.mean())\n",
    "\n",
    "        # Embedding cosine similarity\n",
    "        pe = embeddings[p_name]\n",
    "        le = embeddings[l_name]\n",
    "        cos = (pe @ le) / (pe.norm() * le.norm())\n",
    "\n",
    "        rows.append({\n",
    "            \"Pipeline\":       p_name,\n",
    "            \"LLM\":            l_name,\n",
    "            \"BERTScore_P\":    bP,\n",
    "            \"BERTScore_R\":    bR,\n",
    "            \"BERTScore_F1\":   bF1,\n",
    "            \"Embed_Cosine\":   float(cos)\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc0be69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>LLM</th>\n",
       "      <th>BERTScore_P</th>\n",
       "      <th>BERTScore_R</th>\n",
       "      <th>BERTScore_F1</th>\n",
       "      <th>Embed_Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pipeline1</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>0.776396</td>\n",
       "      <td>0.771578</td>\n",
       "      <td>0.773980</td>\n",
       "      <td>0.962389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pipeline2</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>0.777927</td>\n",
       "      <td>0.775032</td>\n",
       "      <td>0.776476</td>\n",
       "      <td>0.954267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pipeline3</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>0.578537</td>\n",
       "      <td>0.707876</td>\n",
       "      <td>0.636704</td>\n",
       "      <td>0.794937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pipeline1</td>\n",
       "      <td>gemini</td>\n",
       "      <td>0.656933</td>\n",
       "      <td>0.767745</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.878521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pipeline2</td>\n",
       "      <td>gemini</td>\n",
       "      <td>0.665038</td>\n",
       "      <td>0.783617</td>\n",
       "      <td>0.719474</td>\n",
       "      <td>0.876309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pipeline3</td>\n",
       "      <td>gemini</td>\n",
       "      <td>0.508684</td>\n",
       "      <td>0.716024</td>\n",
       "      <td>0.594803</td>\n",
       "      <td>0.718989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pipeline1</td>\n",
       "      <td>deepseek</td>\n",
       "      <td>0.667285</td>\n",
       "      <td>0.700117</td>\n",
       "      <td>0.683307</td>\n",
       "      <td>0.936935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pipeline2</td>\n",
       "      <td>deepseek</td>\n",
       "      <td>0.667135</td>\n",
       "      <td>0.701651</td>\n",
       "      <td>0.683958</td>\n",
       "      <td>0.935804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pipeline3</td>\n",
       "      <td>deepseek</td>\n",
       "      <td>0.511285</td>\n",
       "      <td>0.639596</td>\n",
       "      <td>0.568288</td>\n",
       "      <td>0.806194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pipeline       LLM  BERTScore_P  BERTScore_R  BERTScore_F1  Embed_Cosine\n",
       "0  pipeline1   chatgpt     0.776396     0.771578      0.773980      0.962389\n",
       "1  pipeline2   chatgpt     0.777927     0.775032      0.776476      0.954267\n",
       "2  pipeline3   chatgpt     0.578537     0.707876      0.636704      0.794937\n",
       "3  pipeline1    gemini     0.656933     0.767745      0.708029      0.878521\n",
       "4  pipeline2    gemini     0.665038     0.783617      0.719474      0.876309\n",
       "5  pipeline3    gemini     0.508684     0.716024      0.594803      0.718989\n",
       "6  pipeline1  deepseek     0.667285     0.700117      0.683307      0.936935\n",
       "7  pipeline2  deepseek     0.667135     0.701651      0.683958      0.935804\n",
       "8  pipeline3  deepseek     0.511285     0.639596      0.568288      0.806194"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b479357",
   "metadata": {},
   "source": [
    "### Σύντομη Επεξήγηση Μετρικών\n",
    "\n",
    "- **BERTScore Precision (P)**  \n",
    "  Από τα token που παράγει το pipeline, ποιο ποσοστό βρίσκει “αντίστοιχα” token μέσα στην έξοδο του LLM. Μετράει πόσο «στοχευμένη» είναι η παραγωγή του pipeline σε σχέση με την αναφορά(ground truth).\n",
    "\n",
    "- **BERTScore Recall (R)**  \n",
    "  Από τα token που έχει το LLM, ποιο ποσοστό καλύπτεται από τα token του pipeline. Δείχνει πόσο πλήρες είναι το pipeline σε σχέση με την αναφορά(ground truth).\n",
    "\n",
    "- **BERTScore F1**  \n",
    "  Ο  μέσος του Precision και του Recall. Ισορροπεί την ποιότητα (P) με την κάλυψη (R) σε ένα ενιαίο σκορ 0-1.\n",
    "\n",
    "- **Cosine Similarity (Embed_Cosine)**  \n",
    "  Συνητινιμική ομοιότητα ανάμεσα στα ολόκληρα embeddings (διάνυσμα) δύο κειμένων. Τιμή 1 σημαίνει ταυτόσημη κατεύθυνση, 0 σημαίνει ορθογώνια (καμιά σχέση).  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
