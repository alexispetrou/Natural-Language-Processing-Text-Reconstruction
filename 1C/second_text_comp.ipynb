{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d2c90da",
   "metadata": {},
   "source": [
    "## Σε αυτό το σημείο της εργασίες πρέπει να συγκρίνουμε τα 3 pipelines που χρησιμοποιήσαμε στο ερώτημα 1Β μεταξύ τους\n",
    "\n",
    "### Βήματα \n",
    "- Διαβάζουμε τα 3 ανακατσκευασμένα κείμενα\n",
    "- Κάνουμε σύγκριση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebc6fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text=\"\"\n",
    "pipeline1=\"\"\n",
    "pipeline2=\"\"\n",
    "pipeline3=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0560863e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File content successfully loaded into original_text.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('../text_files/text2.txt', 'r', encoding='utf-8') as file:\n",
    "        original_text = file.read()\n",
    "    print(\"File content successfully loaded into original_text.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'text2.txt' was not found. Please make sure the file exists and the path is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13dd6d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File content successfully loaded into pipeline1.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"../text_files/first_pipeline_text2.txt\", 'r', encoding='utf-8') as file:\n",
    "        pipeline1 = file.read()\n",
    "    print(\"File content successfully loaded into pipeline1.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Please make sure the file exists and the path is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15f9e3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File content successfully loaded into pipeline2.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"../text_files/second_pipeline_text2.txt\", 'r', encoding='utf-8') as file:\n",
    "        pipeline2 = file.read()\n",
    "    print(\"File content successfully loaded into pipeline2.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Please make sure the file exists and the path is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "439f0af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File content successfully loaded into pipeline3.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"../text_files/third_pipeline_text2.txt\", 'r', encoding='utf-8') as file:\n",
    "        pipeline3 = file.read()\n",
    "    print(\"File content successfully loaded into pipeline3.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Please make sure the file exists and the path is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c513b36",
   "metadata": {},
   "source": [
    "## Αρχικά θα συγκρίνουμε το πόσο διαφέρει η κάθε ανακατασκευή από το πρωτότυπο κείμενο με μέθοδο cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "610a3a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "def cosine_similarity_logic(original_text,pipeline):\n",
    "    sentences = [original_text, pipeline]\n",
    "    tokenized = [s.lower().split() for s in sentences]\n",
    "    vocab = sorted(set(word for doc in tokenized for word in doc))\n",
    "\n",
    "    tf_matrix = []\n",
    "    for doc in tokenized:\n",
    "        word_counts = Counter(doc)\n",
    "        tf_vector = [word_counts[word] / len(doc) for word in vocab]\n",
    "        tf_matrix.append(tf_vector)\n",
    "        \n",
    "        \n",
    "    N = len(tokenized) \n",
    "    df_vector = [sum(1 for doc in tokenized if word in doc) for word in vocab]\n",
    "    idf_vector = [np.log((N + 1) / (df + 1)) + 1 for df in df_vector]\n",
    "    tfidf_matrix = np.array(tf_matrix) * np.array(idf_vector)\n",
    "    \n",
    "    \n",
    "    similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "    print(f\"Cosine Similarity: {similarity}\")\n",
    "    \n",
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e904d882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9032013745350934\n",
      "Cosine Similarity: 0.9100695080697159\n",
      "Cosine Similarity: 0.6461714378179904\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_logic(original_text,pipeline1)\n",
    "cosine_similarity_logic(original_text,pipeline2)\n",
    "cosine_similarity_logic(original_text,pipeline3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939b6e1",
   "metadata": {},
   "source": [
    "## Ground truth κείμενο από το gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dbad532",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini=\"\"\"During our last discussion, I mentioned the new submission we've been awaiting since last autumn. The updates were a bit unclear, as they didn't seem to include full reviewer or editor feedback.\n",
    "\n",
    "Despite some recent delays and less frequent communication, I believe the team truly put in their best effort for the paper and our collaboration. We should all be grateful for the acceptance and the hard work that led to the Springer link finally appearing last week.\n",
    "\n",
    "Could you please remind me if the doctor still plans to edit the acknowledgments section before resubmitting? I haven't seen that part finalized yet, and I apologize if I missed it.\n",
    "\n",
    "Let's ensure everyone is safe and celebrate this outcome with some strong coffee as we look to future goals!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0645376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.6292970464242968\n",
      "Cosine Similarity: 0.6435868454573861\n",
      "Cosine Similarity: 0.5042018246913165\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_logic(gemini,pipeline1)\n",
    "cosine_similarity_logic(gemini,pipeline2)\n",
    "cosine_similarity_logic(gemini,pipeline3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4264de",
   "metadata": {},
   "source": [
    "## Ground truth κείμενο από το deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c02fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek=\"\"\"During our final discussion, I mentioned the new submission—the one we’ve been waiting for since last autumn. However, the updates were a bit confusing, as they didn’t seem to include the reviewers’ or editor’s full feedback.\n",
    "\n",
    "That said, I truly believe the team, despite recent delays and limited communication, did their best for the paper and our collaboration. We should all be grateful for the acceptance and their efforts, especially now that the Springer link is finally available (as of last week, I believe).\n",
    "\n",
    "Also, could you kindly confirm whether the doctor still plans to edit the acknowledgments section before resubmitting? I haven’t seen the final version of that part yet—or perhaps I missed it. If so, I apologize.\n",
    "\n",
    "In any case, let’s ensure everything is in order, celebrate this achievement with strong coffee, and focus on our next goals!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6042aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.6382258047137673\n",
      "Cosine Similarity: 0.6592709455115673\n",
      "Cosine Similarity: 0.49522647560750943\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_logic(deepseek,pipeline1)\n",
    "cosine_similarity_logic(deepseek,pipeline2)\n",
    "cosine_similarity_logic(deepseek,pipeline3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3099f3",
   "metadata": {},
   "source": [
    "## Ground truth κείμενο από το chat gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed2e372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_gpt=\"\"\"During our final discussion, I mentioned the new submission — the one we have been waiting for since last autumn. However, the updates were confusing because they did not include the full feedback from the reviewer or possibly the editor.\n",
    "\n",
    "Nevertheless, I believe the team, despite some delays and reduced communication in recent days, has truly done their best for the paper and the collaboration. We should all be grateful for the acceptance and the hard work, especially now that the Springer link finally came out last week, I believe.\n",
    "\n",
    "Also, please kindly remind me if the doctor still plans to edit the acknowledgments section before sending it again. I haven’t seen the final version of that part yet, but I may have missed it—apologies if so.\n",
    "\n",
    "Overall, let’s make sure everyone stays safe and celebrate this achievement with strong coffee and new goals ahead.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f57f4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.7355473565481143\n",
      "Cosine Similarity: 0.7490192052576788\n",
      "Cosine Similarity: 0.5815827923398523\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_logic(chat_gpt,pipeline1)\n",
    "cosine_similarity_logic(chat_gpt,pipeline2)\n",
    "cosine_similarity_logic(chat_gpt,pipeline3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
