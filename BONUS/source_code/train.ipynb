{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74d6942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Φορτώνει τον tokenizer και το μοντέλο 'nlpaueb/bert-base-greek-uncased-v1'...\n",
      "Tokenizer και μοντέλο φορτώθηκαν επιτυχώς.\n",
      "\n",
      "Φορτώνει δεδομένα από το αρχείο: C:\\Users\\alexi\\OneDrive\\Υπολογιστής\\NLP\\BONUS\\source_code\\training_data.txt\n",
      "Το περιεχόμενο του αρχείου φορτώθηκε επιτυχώς. Αριθμός παραδειγμάτων: 7088\n",
      "Το dataset διαιρέθηκε: Train set: 3600 παραδείγματα, Test set: 400 παραδείγματα.\n",
      "\n",
      "Ξεκινάει το Tokenization του dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3600/3600 [00:00<00:00, 11217.69 examples/s]\n",
      "Map: 100%|██████████| 400/400 [00:00<00:00, 9003.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Το Tokenization ολοκληρώθηκε.\n",
      "\n",
      "Ξεκινάει το fine-tuning του μοντέλου (χωρίς αποθήκευση στο δίσκο)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [225/225 18:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Το fine-tuning ολοκληρώθηκε.\n",
      "\n",
      "--- Δοκιμή του μοντέλου (που βρίσκεται στη μνήμη) ---\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import pipeline # Προστέθηκε για το pipeline\n",
    "import os\n",
    "import shutil # Προστέθηκε για το shutil.rmtree\n",
    "\n",
    "# 1. Ρυθμίσεις\n",
    "model_name = \"nlpaueb/bert-base-greek-uncased-v1\"\n",
    "# Δεν ορίζουμε output_dir για αποθήκευση, καθώς δεν θα αποθηκεύσουμε\n",
    "text_file_path = r'C:\\Users\\alexi\\OneDrive\\Υπολογιστής\\NLP\\BONUS\\source_code\\training_data.txt'\n",
    "\n",
    "# 2. Φόρτωση Tokenizer & Μοντέλου\n",
    "print(f\"Φορτώνει τον tokenizer και το μοντέλο '{model_name}'...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "print(\"Tokenizer και μοντέλο φορτώθηκαν επιτυχώς.\")\n",
    "\n",
    "# 3. Φόρτωση Dataset\n",
    "try:\n",
    "    print(f\"\\nΦορτώνει δεδομένα από το αρχείο: {text_file_path}\")\n",
    "    with open(text_file_path, 'r', encoding='utf-8') as f:\n",
    "        # Διαβάζει γραμμές και αφαιρεί κενές, κάθε γραμμή είναι ένα παράδειγμα\n",
    "        lines = [line.strip() for line in f if line.strip()] \n",
    "    \n",
    "    raw_dataset = Dataset.from_dict({\"text\": lines})\n",
    "    print(f\"Το περιεχόμενο του αρχείου φορτώθηκε επιτυχώς. Αριθμός παραδειγμάτων: {len(raw_dataset)}\")\n",
    "\n",
    "    # **ΣΗΜΑΝΤΙΚΟ:** Διαίρεση του dataset σε train και test splits\n",
    "    # Διατηρείται ο περιορισμός στα 1000 παραδείγματα όπως τον είχες\n",
    "    small_dataset = raw_dataset.select(range(min(4000, len(raw_dataset)))) \n",
    "    train_test_split_dataset = small_dataset.train_test_split(test_size=0.1) \n",
    "    print(f\"Το dataset διαιρέθηκε: Train set: {len(train_test_split_dataset['train'])} παραδείγματα, Test set: {len(train_test_split_dataset['test'])} παραδείγματα.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Σφάλμα: Το αρχείο '{text_file_path}' δεν βρέθηκε. Βεβαιωθείτε ότι το αρχείο υπάρχει και η διαδρομή είναι σωστή.\")\n",
    "    exit() \n",
    "except Exception as e:\n",
    "    print(f\"Προέκυψε ένα απροσδόκητο σφάλμα: {e}\")\n",
    "    exit() \n",
    "\n",
    "# 4. Tokenization\n",
    "# Διατηρείται το max_length=64 όπως το είχες\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "\n",
    "print(\"\\nΞεκινάει το Tokenization του dataset...\")\n",
    "# Εφαρμογή της λειτουργίας tokenization στο DatasetDict (train και test splits)\n",
    "tokenized_dataset = train_test_split_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "print(\"Το Tokenization ολοκληρώθηκε.\")\n",
    "\n",
    "# 5. Data collator για [MASK] tokens\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "# 6. Ορισμός Training Arguments\n",
    "# Διατηρείται ο προσωρινός φάκελος και οι ρυθμίσεις για μη αποθήκευση όπως τις είχες\n",
    "temp_output_dir = \"./temp_trainer_output\" # Προσωρινός φάκελος για λογαριασμό του Trainer\n",
    "if not os.path.exists(temp_output_dir):\n",
    "    os.makedirs(temp_output_dir)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=temp_output_dir,           # Προσωρινός κατάλογος για logs/internal checkpoints (δεν αποθηκεύουμε το τελικό)\n",
    "    overwrite_output_dir=True,            # Αντικαθιστά τα υπάρχοντα αποτελέσματα στον temp_output_dir\n",
    "    num_train_epochs=1,                   # Αριθμός εποχών εκπαίδευσης (διατηρείται η 1 εποχή)\n",
    "    per_device_train_batch_size=16,       # Μέγεθος batch ανά συσκευή (GPU/CPU)\n",
    "    save_steps=-1,                        # Απενεργοποιεί την αποθήκευση checkpoints\n",
    "    save_total_limit=0,                   # Δεν διατηρεί καθόλου checkpoints\n",
    "    prediction_loss_only=True,            \n",
    "    report_to=\"none\",                     # Απενεργοποιεί την αναφορά σε external services (π.χ. W&B)\n",
    ")\n",
    "\n",
    "# 7. Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"], \n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# 8. Εκκίνηση fine-tuning\n",
    "print(\"\\nΞεκινάει το fine-tuning του μοντέλου (χωρίς αποθήκευση στο δίσκο)...\")\n",
    "trainer.train()\n",
    "print(\"Το fine-tuning ολοκληρώθηκε.\")\n",
    "\n",
    "# 9. Δεν υπάρχει βήμα αποθήκευσης του μοντέλου/tokenizer εδώ.\n",
    "\n",
    "# 10. Δοκιμή του fine-tuned μοντέλου\n",
    "print(\"\\n--- Δοκιμή του μοντέλου (που βρίσκεται στη μνήμη) ---\")\n",
    "# Χρησιμοποιούμε απ' ευθείας το trainer.model που είναι το εκπαιδευμένο μοντέλο στη μνήμη.\n",
    "fill_mask_pipeline = pipeline(\"fill-mask\", model=trainer.model, tokenizer=tokenizer)\n",
    "\n",
    "# Παράδειγμα πρόβλεψης που έχεις δώσει\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36c375d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Αρχικό κείμενο για συμπλήρωση:\n",
      "'Πραγματική δουλεία σε [MASK] η υπέρ του κοινού ακινήτου. — Στο κοινό \n",
      "[MASK] μπορεί να συσταθεί πραγματική δουλεία υπέρ του [MASK] κύριου άλλου ακινήτου \n",
      "και αν ακόμη αυτός είναι [MASK] του ακινήτου που βαρύνεται με τη δουλεία. Το ίδιο ισχύει \n",
      "και για την [MASK] δουλεία πάνω σε ακίνητο υπέρ των εκάστοτε κυρίων κοινού ακινήτου, \n",
      "αν [MASK] από αυτούς είναι κύριος του [MASK] που βαρύνεται με τη δουλεία. '\n",
      "------------------------------------------------------------\n",
      "--- Καλύτερη πρόβλεψη για το [MASK] 1 ---\n",
      "'[CLS] πραγματικη δουλεια σε ακινητο η υπερ του κοινου ακινητου. — στο κοινο [MASK] μπορει να συσταθει πραγματικη δουλεια υπερ του [MASK] κυριου αλλου ακινητου και αν ακομη αυτος ειναι [MASK] του ακινητου που βαρυνεται με τη δουλεια. το ιδιο ισχυει και για την [MASK] δουλεια πανω σε ακινητο υπερ των εκαστοτε κυριων κοινου ακινητου, αν [MASK] απο αυτους ειναι κυριος του [MASK] που βαρυνεται με τη δουλεια. [SEP]' (Πιθανότητα: 0.4677, Λέξη: 'ακινητο')\n",
      "------------------------------------------------------------\n",
      "--- Καλύτερη πρόβλεψη για το [MASK] 2 ---\n",
      "'[CLS] πραγματικη δουλεια σε [MASK] η υπερ του κοινου ακινητου. — στο κοινο ακινητο μπορει να συσταθει πραγματικη δουλεια υπερ του [MASK] κυριου αλλου ακινητου και αν ακομη αυτος ειναι [MASK] του ακινητου που βαρυνεται με τη δουλεια. το ιδιο ισχυει και για την [MASK] δουλεια πανω σε ακινητο υπερ των εκαστοτε κυριων κοινου ακινητου, αν [MASK] απο αυτους ειναι κυριος του [MASK] που βαρυνεται με τη δουλεια. [SEP]' (Πιθανότητα: 0.3176, Λέξη: 'ακινητο')\n",
      "------------------------------------------------------------\n",
      "--- Καλύτερη πρόβλεψη για το [MASK] 3 ---\n",
      "'[CLS] πραγματικη δουλεια σε [MASK] η υπερ του κοινου ακινητου. — στο κοινο [MASK] μπορει να συσταθει πραγματικη δουλεια υπερ του κυριου κυριου αλλου ακινητου και αν ακομη αυτος ειναι [MASK] του ακινητου που βαρυνεται με τη δουλεια. το ιδιο ισχυει και για την [MASK] δουλεια πανω σε ακινητο υπερ των εκαστοτε κυριων κοινου ακινητου, αν [MASK] απο αυτους ειναι κυριος του [MASK] που βαρυνεται με τη δουλεια. [SEP]' (Πιθανότητα: 0.6823, Λέξη: 'κυριου')\n",
      "------------------------------------------------------------\n",
      "--- Καλύτερη πρόβλεψη για το [MASK] 4 ---\n",
      "'[CLS] πραγματικη δουλεια σε [MASK] η υπερ του κοινου ακινητου. — στο κοινο [MASK] μπορει να συσταθει πραγματικη δουλεια υπερ του [MASK] κυριου αλλου ακινητου και αν ακομη αυτος ειναι κυριος του ακινητου που βαρυνεται με τη δουλεια. το ιδιο ισχυει και για την [MASK] δουλεια πανω σε ακινητο υπερ των εκαστοτε κυριων κοινου ακινητου, αν [MASK] απο αυτους ειναι κυριος του [MASK] που βαρυνεται με τη δουλεια. [SEP]' (Πιθανότητα: 0.9943, Λέξη: 'κυριος')\n",
      "------------------------------------------------------------\n",
      "--- Καλύτερη πρόβλεψη για το [MASK] 5 ---\n",
      "'[CLS] πραγματικη δουλεια σε [MASK] η υπερ του κοινου ακινητου. — στο κοινο [MASK] μπορει να συσταθει πραγματικη δουλεια υπερ του [MASK] κυριου αλλου ακινητου και αν ακομη αυτος ειναι [MASK] του ακινητου που βαρυνεται με τη δουλεια. το ιδιο ισχυει και για την πραγματικη δουλεια πανω σε ακινητο υπερ των εκαστοτε κυριων κοινου ακινητου, αν [MASK] απο αυτους ειναι κυριος του [MASK] που βαρυνεται με τη δουλεια. [SEP]' (Πιθανότητα: 0.4887, Λέξη: 'πραγματικη')\n",
      "------------------------------------------------------------\n",
      "--- Καλύτερη πρόβλεψη για το [MASK] 6 ---\n",
      "'[CLS] πραγματικη δουλεια σε [MASK] η υπερ του κοινου ακινητου. — στο κοινο [MASK] μπορει να συσταθει πραγματικη δουλεια υπερ του [MASK] κυριου αλλου ακινητου και αν ακομη αυτος ειναι [MASK] του ακινητου που βαρυνεται με τη δουλεια. το ιδιο ισχυει και για την [MASK] δουλεια πανω σε ακινητο υπερ των εκαστοτε κυριων κοινου ακινητου, αν ενας απο αυτους ειναι κυριος του [MASK] που βαρυνεται με τη δουλεια. [SEP]' (Πιθανότητα: 0.4065, Λέξη: 'ενας')\n",
      "------------------------------------------------------------\n",
      "--- Καλύτερη πρόβλεψη για το [MASK] 7 ---\n",
      "'[CLS] πραγματικη δουλεια σε [MASK] η υπερ του κοινου ακινητου. — στο κοινο [MASK] μπορει να συσταθει πραγματικη δουλεια υπερ του [MASK] κυριου αλλου ακινητου και αν ακομη αυτος ειναι [MASK] του ακινητου που βαρυνεται με τη δουλεια. το ιδιο ισχυει και για την [MASK] δουλεια πανω σε ακινητο υπερ των εκαστοτε κυριων κοινου ακινητου, αν [MASK] απο αυτους ειναι κυριος του ακινητου που βαρυνεται με τη δουλεια. [SEP]' (Πιθανότητα: 0.9827, Λέξη: 'ακινητου')\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Συμπληρωμένη Παράγραφος από το Μοντέλο ---\n",
      "Πραγματική δουλεία σε ακινητο η υπέρ του κοινού ακινήτου. — Στο κοινό \n",
      "ακινητο μπορεί να συσταθεί πραγματική δουλεία υπέρ του κυριου κύριου άλλου ακινήτου \n",
      "και αν ακόμη αυτός είναι κυριος του ακινήτου που βαρύνεται με τη δουλεία. Το ίδιο ισχύει \n",
      "και για την πραγματικη δουλεία πάνω σε ακίνητο υπέρ των εκάστοτε κυρίων κοινού ακινήτου, \n",
      "αν ενας από αυτούς είναι κύριος του ακινητου που βαρύνεται με τη δουλεία. \n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Σύγκριση: Ground Truth vs Πρόβλεψη Μοντέλου (Αναλυτικό) ---\n",
      "- Πραγματικη Δουλεια υπερ κοινου ακινητου. - Στο κοινο ακινητο μπορει να συσταθει πραγματικη δουλεια υπερ του εκαστοτε κυριου αλλου ακινητου και αν ακομη αυτος ειναι συγκυριος του ακινητου που βαρυνεται με τη δουλεια. Το ιδιο ισχυει και για πραγματικη δουλεια πανω σε ακινητο υπερ των εκαστοτε κυριων κοινου ακινητου, αν καποιος απο αυτους ειναι κυριος του ακινητου που βαρυνεται με τη δουλεια.\n",
      "+ Πραγματικη δουλεια σε ακινητο η υπερ του κοινου ακινητου.— Στο κοινο ακινητο μπορει να συσταθει πραγματικη δουλεια υπερ του κυριου κυριου αλλου ακινητου και αν ακομη αυτος ειναι κυριος του ακινητου που βαρυνεται με τη δουλεια. Το ιδιο ισχυει και για την πραγματικη δουλεια πανω σε ακινητο υπερ των εκαστοτε κυριων κοινου ακινητου, αν ενας απο αυτους ειναι κυριος του ακινητου που βαρυνεται με τη δουλεια.\n",
      "\n",
      "Οδηγίες σύγκρισης (από το difflib):\n",
      "  ' ' : γραμμή ίδια\n",
      "  '-' : γραμμή που υπάρχει μόνο στο πρώτο κείμενο\n",
      "  '+' : γραμμή που υπάρχει μόνο στο δεύτερο κείμενο\n",
      "  '?' : δείχνει τις διαφορές χαρακτήρων μέσα σε μια γραμμή (με ^)\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Ποσοτική Αξιολόγηση Λέξεων [MASK] ---\n",
      "Συγκρίνοντας 7 MASKed θέσεις:\n",
      "  MASK 1: Πρόβλεψη='ακινητο' (κανονικοποιημένο: 'ακινητο') | Σωστό='ακίνητο' (κανονικοποιημένο: 'ακινητο') -> ✔ Σωστό\n",
      "  MASK 2: Πρόβλεψη='ακινητο' (κανονικοποιημένο: 'ακινητο') | Σωστό='ακίνητο' (κανονικοποιημένο: 'ακινητο') -> ✔ Σωστό\n",
      "  MASK 3: Πρόβλεψη='κυριου' (κανονικοποιημένο: 'κυριου') | Σωστό='εκάστοτε' (κανονικοποιημένο: 'εκαστοτε') -> ✖ Λάθος\n",
      "  MASK 4: Πρόβλεψη='κυριος' (κανονικοποιημένο: 'κυριος') | Σωστό='συγκύριος' (κανονικοποιημένο: 'συγκυριος') -> ✖ Λάθος\n",
      "  MASK 5: Πρόβλεψη='πραγματικη' (κανονικοποιημένο: 'πραγματικη') | Σωστό='πραγματική' (κανονικοποιημένο: 'πραγματικη') -> ✔ Σωστό\n",
      "  MASK 6: Πρόβλεψη='ενας' (κανονικοποιημένο: 'ενας') | Σωστό='κάποιος' (κανονικοποιημένο: 'καποιος') -> ✖ Λάθος\n",
      "  MASK 7: Πρόβλεψη='ακινητου' (κανονικοποιημένο: 'ακινητου') | Σωστό='ακινήτου' (κανονικοποιημένο: 'ακινητου') -> ✔ Σωστό\n",
      "\n",
      "Αποτελέσματα:\n",
      "  Συνολικές προβλέψεις MASK: 7\n",
      "  Σωστές προβλέψεις MASK: 4\n",
      "  Ακρίβεια (masked words accuracy): 57.14%\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- ΝΕΑ ΣΥΝΑΡΤΗΣΗ ΓΙΑ ΣΥΜΠΛΗΡΩΣΗ ΠΑΡΑΓΡΑΦΟΥ ---\n",
    "import unicodedata\n",
    "def remove_greek_accents(text):\n",
    "    \"\"\"\n",
    "    Αφαιρεί τους ελληνικούς τόνους από μια συμβολοσειρά.\n",
    "    \"\"\"\n",
    "    # Κανονικοποιεί τη συμβολοσειρά σε μορφή NFD (Normalization Form Canonical Decomposition)\n",
    "    # όπου οι τόνοι διαχωρίζονται από τα γράμματα.\n",
    "    # Στη συνέχεια, φιλτράρει τους χαρακτήρες που είναι \"mark\" (όπως οι τόνοι).\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "# --- ΝΕΑ ΣΥΝΑΡΤΗΣΗ ΓΙΑ ΣΥΜΠΛΗΡΩΣΗ ΠΑΡΑΓΡΑΦΟΥ ---\n",
    "def fill_and_display_paragraph(text_with_masks: str, fm_pipeline) -> tuple[str, list[str]]:\n",
    "    \"\"\"\n",
    "    Συμπληρώνει ένα κείμενο με [MASK] tokens χρησιμοποιώντας το fill-mask pipeline,\n",
    "    εκτυπώνει τις καλύτερες προβλέψεις και επιστρέφει την συμπληρωμένη παράγραφο\n",
    "    και τη λίστα με τις προβλεφθείσες λέξεις.\n",
    "\n",
    "    Args:\n",
    "        text_with_masks (str): Το κείμενο που περιέχει τα [MASK] tokens.\n",
    "        fm_pipeline: Το Hugging Face fill-mask pipeline.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, list[str]]: Η παράγραφος με όλα τα [MASK] tokens συμπληρωμένα\n",
    "                                και μια λίστα με τις προβλεφθείσες λέξεις (στη σειρά).\n",
    "    \"\"\"\n",
    "    print(f\"Αρχικό κείμενο για συμπλήρωση:\")\n",
    "    print(f\"'{text_with_masks}'\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    predictions_for_text = fm_pipeline(text_with_masks, top_k=1)\n",
    "\n",
    "    predicted_words = [] \n",
    "\n",
    "    for mask_idx, mask_predictions in enumerate(predictions_for_text):\n",
    "        if mask_predictions:\n",
    "            best_prediction = mask_predictions[0] \n",
    "            predicted_word = best_prediction['token_str']\n",
    "            predicted_words.append(predicted_word) \n",
    "\n",
    "            print(f\"--- Καλύτερη πρόβλεψη για το [MASK] {mask_idx + 1} ---\")\n",
    "            print(f\"'{best_prediction['sequence']}' (Πιθανότητα: {best_prediction['score']:.4f}, Λέξη: '{predicted_word}')\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    completed_paragraph = text_with_masks\n",
    "    for word in predicted_words:\n",
    "        completed_paragraph = re.sub(r'\\[MASK\\]', word, completed_paragraph, 1)\n",
    "\n",
    "    print(\"\\n--- Συμπληρωμένη Παράγραφος από το Μοντέλο ---\")\n",
    "    print(completed_paragraph)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    return completed_paragraph, predicted_words \n",
    "\n",
    "# --- ΣΥΝΑΡΤΗΣΗ ΓΙΑ ΣΥΓΚΡΙΣΗ ΚΕΙΜΕΝΩΝ (difflib) ---\n",
    "def compare_texts(text1: str, text2: str, label1=\"Κείμενο 1\", label2=\"Κείμενο 2\"):\n",
    "    print(f\"\\n--- Σύγκριση: {label1} vs {label2} (Αναλυτικό) ---\")\n",
    "    \n",
    "    # Εφαρμόζουμε remove_greek_accents πριν τον καθαρισμό και τη σύγκριση\n",
    "    cleaned_text1 = \" \".join(remove_greek_accents(text1).split()).replace(\" .\", \".\").replace(\" ,\", \",\").replace(\" —\", \"—\")\n",
    "    cleaned_text2 = \" \".join(remove_greek_accents(text2).split()).replace(\" .\", \".\").replace(\" ,\", \",\").replace(\" —\", \"—\")\n",
    "\n",
    "    differ = difflib.Differ()\n",
    "    diff = list(differ.compare(cleaned_text1.splitlines(), cleaned_text2.splitlines()))\n",
    "\n",
    "    for line in diff:\n",
    "        print(line)\n",
    "\n",
    "    print(\"\\nΟδηγίες σύγκρισης (από το difflib):\")\n",
    "    print(\"  ' ' : γραμμή ίδια\")\n",
    "    print(\"  '-' : γραμμή που υπάρχει μόνο στο πρώτο κείμενο\")\n",
    "    print(\"  '+' : γραμμή που υπάρχει μόνο στο δεύτερο κείμενο\")\n",
    "    print(\"  '?' : δείχνει τις διαφορές χαρακτήρων μέσα σε μια γραμμή (με ^)\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# --- ΠΑΡΑΔΕΙΓΜΑ ΧΡΗΣΗΣ ---\n",
    "\n",
    "# Το κείμενο με τα MASK tokens που θα δώσουμε στο μοντέλο\n",
    "text_to_fill = \"\"\"Πραγματική δουλεία σε [MASK] η υπέρ του κοινού ακινήτου. — Στο κοινό \n",
    "[MASK] μπορεί να συσταθεί πραγματική δουλεία υπέρ του [MASK] κύριου άλλου ακινήτου \n",
    "και αν ακόμη αυτός είναι [MASK] του ακινήτου που βαρύνεται με τη δουλεία. Το ίδιο ισχύει \n",
    "και για την [MASK] δουλεία πάνω σε ακίνητο υπέρ των εκάστοτε κυρίων κοινού ακινήτου, \n",
    "αν [MASK] από αυτούς είναι κύριος του [MASK] που βαρύνεται με τη δουλεία. \"\"\"\n",
    "\n",
    "# Το ground truth κείμενο για σύγκριση\n",
    "ground_truth_text = \"\"\" Πραγματική  Δουλεία υπέρ κοινού ακινήτου. - Στο κοινό ακίνητο μπορεί να συσταθεί πραγματική δουλεία υπέρ του\n",
    " εκάστοτε κυρίου άλλου ακινήτου και αν ακόμη αυτός είναι συγκύριος του\n",
    " ακινήτου που βαρύνεται με τη δουλεία. Το ίδιο ισχύει και για πραγματική\n",
    " δουλεία πάνω σε ακίνητο υπέρ των εκάστοτε κυρίων κοινού ακινήτου, αν\n",
    " κάποιος από αυτούς είναι κύριος του ακινήτου που βαρύνεται με τη\n",
    " δουλεία.\"\"\"\n",
    "\n",
    "# **Οι σωστές λέξεις που αντιστοιχούν σε κάθε [MASK] με τη σειρά.**\n",
    "# Τώρα, μπορούμε να τις γράψουμε και με τόνους, καθώς η συνάρτηση αξιολόγησης θα τους αφαιρέσει\n",
    "correct_masked_words = [\"ακίνητο\", \"ακίνητο\", \"εκάστοτε\", \"συγκύριος\", \"πραγματική\", \"κάποιος\", \"ακινήτου\"]\n",
    "\n",
    "# 1. Συμπληρώνουμε την παράγραφο χρησιμοποιώντας τη συνάρτηση\n",
    "predicted_paragraph, predicted_words_list = fill_and_display_paragraph(text_to_fill, fill_mask_pipeline)\n",
    "\n",
    "# 2. Συγκρίνουμε την συμπληρωμένη παράγραφο με το ground truth (αναλυτικά)\n",
    "compare_texts(ground_truth_text, predicted_paragraph, \n",
    "              label1=\"Ground Truth\", label2=\"Πρόβλεψη Μοντέλου\")\n",
    "\n",
    "# 3. Ποσοτική Αξιολόγηση των προβλεφθέντων λέξεων\n",
    "print(\"\\n--- Ποσοτική Αξιολόγηση Λέξεων [MASK] ---\")\n",
    "\n",
    "if len(predicted_words_list) != len(correct_masked_words):\n",
    "    print(\"Προσοχή: Ο αριθμός των προβλεφθέντων λέξεων δεν ταιριάζει με τον αριθμό των σωστών λέξεων.\")\n",
    "    print(f\"Προβλεφθείσες: {len(predicted_words_list)}, Σωστές: {len(correct_masked_words)}\")\n",
    "else:\n",
    "    correct_predictions_count = 0\n",
    "    total_masks = len(correct_masked_words)\n",
    "\n",
    "    print(f\"Συγκρίνοντας {total_masks} MASKed θέσεις:\")\n",
    "    for i in range(total_masks):\n",
    "        # Εφαρμόζουμε remove_greek_accents και lower() και στις δύο λέξεις\n",
    "        pred_word_normalized = remove_greek_accents(predicted_words_list[i]).strip().lower()\n",
    "        corr_word_normalized = remove_greek_accents(correct_masked_words[i]).strip().lower()\n",
    "\n",
    "        if pred_word_normalized == corr_word_normalized:\n",
    "            correct_predictions_count += 1\n",
    "            status = \"✔ Σωστό\"\n",
    "        else:\n",
    "            status = \"✖ Λάθος\"\n",
    "        print(f\"  MASK {i+1}: Πρόβλεψη='{predicted_words_list[i]}' (κανονικοποιημένο: '{pred_word_normalized}') | Σωστό='{correct_masked_words[i]}' (κανονικοποιημένο: '{corr_word_normalized}') -> {status}\")\n",
    "\n",
    "    accuracy = (correct_predictions_count / total_masks) * 100\n",
    "    print(f\"\\nΑποτελέσματα:\")\n",
    "    print(f\"  Συνολικές προβλέψεις MASK: {total_masks}\")\n",
    "    print(f\"  Σωστές προβλέψεις MASK: {correct_predictions_count}\")\n",
    "    print(f\"  Ακρίβεια (masked words accuracy): {accuracy:.2f}%\")\n",
    "\n",
    "print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e91a1804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Αρχικό κείμενο για συμπλήρωση:\n",
      "'Κοινό πράγμα. — Αν η κυριότητα του [MASK]  ανήκει σε περισσότερους \n",
      "[MASK] αδιαιρέτου κατ΄ιδανικά [MASK], εφαρμόζονται οι διατάξεις για την κοινωνία. '\n",
      "------------------------------------------------------------\n",
      "--- Καλύτερη πρόβλεψη για το [MASK] 1 ---\n",
      "'[CLS] κοινο πραγμα. — αν η κυριοτητα του κοινου ανηκει σε περισσοτερους [MASK] αδιαιρετου κατ΄ιδανικα [MASK], εφαρμοζονται οι διαταξεις για την κοινωνια. [SEP]' (Πιθανότητα: 0.3748, Λέξη: 'κοινου')\n",
      "------------------------------------------------------------\n",
      "--- Καλύτερη πρόβλεψη για το [MASK] 2 ---\n",
      "'[CLS] κοινο πραγμα. — αν η κυριοτητα του [MASK] ανηκει σε περισσοτερους του αδιαιρετου κατ΄ιδανικα [MASK], εφαρμοζονται οι διαταξεις για την κοινωνια. [SEP]' (Πιθανότητα: 0.5763, Λέξη: 'του')\n",
      "------------------------------------------------------------\n",
      "--- Καλύτερη πρόβλεψη για το [MASK] 3 ---\n",
      "'[CLS] κοινο πραγμα. — αν η κυριοτητα του [MASK] ανηκει σε περισσοτερους [MASK] αδιαιρετου κατ΄ιδανικα μερη, εφαρμοζονται οι διαταξεις για την κοινωνια. [SEP]' (Πιθανότητα: 0.5061, Λέξη: 'μερη')\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Συμπληρωμένη Παράγραφος από το Μοντέλο ---\n",
      "Κοινό πράγμα. — Αν η κυριότητα του κοινου  ανήκει σε περισσότερους \n",
      "του αδιαιρέτου κατ΄ιδανικά μερη, εφαρμόζονται οι διατάξεις για την κοινωνία. \n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Σύγκριση: Ground Truth vs Πρόβλεψη Μοντέλου (Αναλυτικό) ---\n",
      "- Κοινο πραγμα.— Αν η κυριοτητα του πραγματος ανηκει σε περισσοτερους εξ αδιαιρετου κατ΄ιδανικα μερη, εφαρμοζονται οι διαταξεις για την κοινωνια.\n",
      "?                                   ^^^^^^^ ^                         ^^\n",
      "\n",
      "+ Κοινο πραγμα.— Αν η κυριοτητα του κοινου ανηκει σε περισσοτερους του αδιαιρετου κατ΄ιδανικα μερη, εφαρμοζονται οι διαταξεις για την κοινωνια.\n",
      "?                                   ^ ^^^^                         ^^^\n",
      "\n",
      "\n",
      "Οδηγίες σύγκρισης (από το difflib):\n",
      "  ' ' : γραμμή ίδια\n",
      "  '-' : γραμμή που υπάρχει μόνο στο πρώτο κείμενο\n",
      "  '+' : γραμμή που υπάρχει μόνο στο δεύτερο κείμενο\n",
      "  '?' : δείχνει τις διαφορές χαρακτήρων μέσα σε μια γραμμή (με ^)\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Ποσοτική Αξιολόγηση Λέξεων [MASK] ---\n",
      "Συγκρίνοντας 3 MASKed θέσεις:\n",
      "  MASK 1: Πρόβλεψη='κοινου' (κανονικοποιημένο: 'κοινου') | Σωστό='πράγματος' (κανονικοποιημένο: 'πραγματος') -> ✖ Λάθος\n",
      "  MASK 2: Πρόβλεψη='του' (κανονικοποιημένο: 'του') | Σωστό='εξ' (κανονικοποιημένο: 'εξ') -> ✖ Λάθος\n",
      "  MASK 3: Πρόβλεψη='μερη' (κανονικοποιημένο: 'μερη') | Σωστό='μέρη' (κανονικοποιημένο: 'μερη') -> ✔ Σωστό\n",
      "\n",
      "Αποτελέσματα:\n",
      "  Συνολικές προβλέψεις MASK: 3\n",
      "  Σωστές προβλέψεις MASK: 1\n",
      "  Ακρίβεια (masked words accuracy): 33.33%\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Το κείμενο με τα MASK tokens που θα δώσουμε στο μοντέλο\n",
    "text_to_fill = \"\"\"Κοινό πράγμα. — Αν η κυριότητα του [MASK]  ανήκει σε περισσότερους \n",
    "[MASK] αδιαιρέτου κατ΄ιδανικά [MASK], εφαρμόζονται οι διατάξεις για την κοινωνία. \"\"\"\n",
    "\n",
    "# Το ground truth κείμενο για σύγκριση\n",
    "ground_truth_text = \"\"\" Κοινό πράγμα. — Αν η κυριότητα του πράγματος  ανήκει σε περισσότερους \n",
    "εξ αδιαιρέτου κατ΄ιδανικά μέρη, εφαρμόζονται οι διατάξεις για την κοινωνία.\"\"\"\n",
    "\n",
    "# **Οι σωστές λέξεις που αντιστοιχούν σε κάθε [MASK] με τη σειρά.**\n",
    "# Τώρα, μπορούμε να τις γράψουμε και με τόνους, καθώς η συνάρτηση αξιολόγησης θα τους αφαιρέσει\n",
    "correct_masked_words = [\"πράγματος\", \"εξ\", \"μέρη\"]\n",
    "\n",
    "# 1. Συμπληρώνουμε την παράγραφο χρησιμοποιώντας τη συνάρτηση\n",
    "predicted_paragraph, predicted_words_list = fill_and_display_paragraph(text_to_fill, fill_mask_pipeline)\n",
    "\n",
    "# 2. Συγκρίνουμε την συμπληρωμένη παράγραφο με το ground truth (αναλυτικά)\n",
    "compare_texts(ground_truth_text, predicted_paragraph, \n",
    "              label1=\"Ground Truth\", label2=\"Πρόβλεψη Μοντέλου\")\n",
    "\n",
    "# 3. Ποσοτική Αξιολόγηση των προβλεφθέντων λέξεων\n",
    "print(\"\\n--- Ποσοτική Αξιολόγηση Λέξεων [MASK] ---\")\n",
    "\n",
    "if len(predicted_words_list) != len(correct_masked_words):\n",
    "    print(\"Προσοχή: Ο αριθμός των προβλεφθέντων λέξεων δεν ταιριάζει με τον αριθμό των σωστών λέξεων.\")\n",
    "    print(f\"Προβλεφθείσες: {len(predicted_words_list)}, Σωστές: {len(correct_masked_words)}\")\n",
    "else:\n",
    "    correct_predictions_count = 0\n",
    "    total_masks = len(correct_masked_words)\n",
    "\n",
    "    print(f\"Συγκρίνοντας {total_masks} MASKed θέσεις:\")\n",
    "    for i in range(total_masks):\n",
    "        # Εφαρμόζουμε remove_greek_accents και lower() και στις δύο λέξεις\n",
    "        pred_word_normalized = remove_greek_accents(predicted_words_list[i]).strip().lower()\n",
    "        corr_word_normalized = remove_greek_accents(correct_masked_words[i]).strip().lower()\n",
    "\n",
    "        if pred_word_normalized == corr_word_normalized:\n",
    "            correct_predictions_count += 1\n",
    "            status = \"✔ Σωστό\"\n",
    "        else:\n",
    "            status = \"✖ Λάθος\"\n",
    "        print(f\"  MASK {i+1}: Πρόβλεψη='{predicted_words_list[i]}' (κανονικοποιημένο: '{pred_word_normalized}') | Σωστό='{correct_masked_words[i]}' (κανονικοποιημένο: '{corr_word_normalized}') -> {status}\")\n",
    "\n",
    "    accuracy = (correct_predictions_count / total_masks) * 100\n",
    "    print(f\"\\nΑποτελέσματα:\")\n",
    "    print(f\"  Συνολικές προβλέψεις MASK: {total_masks}\")\n",
    "    print(f\"  Σωστές προβλέψεις MASK: {correct_predictions_count}\")\n",
    "    print(f\"  Ακρίβεια (masked words accuracy): {accuracy:.2f}%\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
